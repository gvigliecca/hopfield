# Hopfield
Object oriented implementation of a Hopfield neural nework in Python.
This work examines the problem of memorizing a set of random patterns made up of independent bits which can take the values +1 or -1 with equal probability.
We let the network evolve for different numbers of neurons and stored patterns from all of its memories and measure the superposition of the initial state with the steady state. Plotting the results we observed the famous 0.138N capacity discussed in the book 'Introduction To The Theory Of Neural Computation' by John A. Hertz.
